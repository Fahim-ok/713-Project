# -*- coding: utf-8 -*-
"""electric-power-consumption-eda (2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a3oZApp557tQIEVcGGFaSO3mSdvuIQNR

### Prediction of Electric Power Consumption in an Individual Household

##### import libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""##### Read the data"""

df = pd.read_csv('../input/electric-power-consumption-data-set/household_power_consumption.txt', sep=';',
                  parse_dates={'dt' : ['Date', 'Time']}, infer_datetime_format=True,
                 low_memory=False, na_values=['nan','?'],index_col='dt')

"""### 1. Data include 'nan' and '?' as a string. I converted both to numpy nan in importing stage (above) and treated both of them the same

### 2. I merged two columns 'Date' and 'Time' to 'dt'.
"""

# Check the shape of dataset (No. of rows and No. of Columns)

df.shape

"""Total there were 2075259 observations or rows and 8 Features or columns, but after converting the Date column as index, number of columns left are 7"""

# Check top five records of dataframe

df.head()

# Check last five records of dataframe

df.tail()

"""##### Working with Missing Data

##### The dataset contains some missing values in the measurements (nearly 1.25% of the total rows).
"""

# Check Missing Values

df.isnull().sum()

"""There are total 25979 rows which are Null.

There are multiple ways to handle and fill missing values like mean, median, forward fill, backward fill, scikit learn Imputer methods, etc.

For this problem, we will either use forward fill or backward fill. Reason: The records ahving null values are in between and the power used is recorded at every minute for 3-4 years. ffill() will fill last valid observation in next found Null record
"""

# fill missing values row wise and making the changes permanent in the original dataframe

df.ffill(axis=0,inplace=True)

# Cross check whether all missing values are filled

df.isnull().sum()

"""##### Analysis
1. Weekly
2. Monthly
3. Quarterly
4. Yearly

##### Sub Datasets
1. Power Consumption
2. Sub metering
3. Global Reactive, Global Active and Global Intensity
"""

# Creating Target Variable

eq1 = (df['Global_active_power']*1000/60)
eq2 = df['Sub_metering_1'] + df['Sub_metering_2'] + df['Sub_metering_3']
df['power_consumption'] = eq1 - eq2
df.head()

"""### Creating two more columns from index, Date and Time Column Separately
##### With the help of this new column 'Date', it will be easier to do grouping on the data which willl ease the work of Visualization for better understanding on Data
"""

df['Date'] = df.index.date
df['time'] = df.index.time

# Converting Date Datatype form object to datetime

df['Date'] = pd.to_datetime(df['Date'])

# Checking the data types of all columns

df.info()

"""##### From 2006-12-16 to 2006-12-31 > 16 Days
##### From 2007-01-01 to 2007-12-31 > 365 Days
##### From 2008-01-01 to 2008-12-31 > 366 Days
##### From 2009-01-01 to 2009-12-31 > 365 Days
##### From 2010-01-01 to 2010-11-26 > 330 Days

##### Total Days: 1442 days

As we have only 16 records for 2006 year, which may deceive our analysis. As we will analyse the data yearly and this 16 records will not help us understand the data flow for the year 2006. We will remove those 16 records of 2006 and move ahead for analysis of remaining four year data.

Reason of unavailabilty of data for 2006 could be, data collection might have started for analysis if from 16th december 2006 or else the previous data might have lost due to some serious problem or due to unavailabilty of proper required data for analysis like missing of some features or so.
"""

# filter out 2006 data, only keep data post 2006
df = df[df.index.year>2006]

# Printing first five records of dataframe
df.head()

# printing No. of rows and No. of columns
df.shape

"""### We will create sub datasets from original dataset
##### As we have data for each minute for each day, we will group the data day-wise, so we will get dataset for per day (where all each minute data is grouped for same date)
"""

# Grouping the entire data by Date

df_data = df.groupby(['Date']).sum()

# Check whether the data is grouped day-wise

df_data.head()

# check No. of rows and No. of columns

df_data.shape

"""### Create all three Sub-DataFrame from original dataframe.

##### Power_consumption: It represents the active energy consumed every day (in watt hour) in the household by electrical equipment not measured in sub-meterings 1, 2 and 3.
"""

# Creating sub-dataframe of power consumption (measured in watt-hour)

##### Every 1 Watt-hour = 0.001 Kilowatt-hour. Example: 25000 Watt-hour = 25000 multiplied by 0.001 = 25 Kilowatt-hour.

df_power_consumption = df_data[['power_consumption']]

# Check top five records

df_power_consumption.head()

"""##### sub_metering_1:  It corresponds to the kitchen, containing mainly a dishwasher, an oven and a microwave (hot plates are not electric but gas powered).

##### sub_metering_2: It corresponds to the laundry room, containing a washing-machine, a tumble-drier, a refrigerator and a light.

##### sub_metering_2:  It corresponds to an electric water-heater and an air-conditioner.
"""

# Creating sub-dataframe of sub-metering 1, sub-metering 2, and sub-metering 3 (measured in watt-hour)

df_sub_meterings = df_data[['Sub_metering_1','Sub_metering_2','Sub_metering_3']]

# Check first five records

df_sub_meterings.head()

# Creating sub-dataframe of Global_active_power, Global_reactive_power, and Global_intensity
# (Global_active_power and Global_reactive_power measured in kilowatt whereas, Global_intensity measured in Ampere)
# kilowatt = (ampere * volt) / 1000


df_active_reactive = df_data[['Global_active_power','Global_reactive_power','Global_intensity']]

# Check first five records

df_active_reactive.head()

"""### Analysis of Power Consumption Yearly"""

# Checking Statistical summary of power consumption yearly

df_power_consumption.groupby(df_power_consumption.index.year).describe()

"""### Observation:
1. for 2006, there are only 16 records, where are for other years there are 300+ records, which describes slightly imbalance in dataset, due to which values are bit disturbed compared to other years.

### We will visualize the power consumption column using bar chart

##### Four types of aggregation (Sum, Max, Min, Mean) each for Weekly, Monthly, Quarterly and Yearly Aanalysis.
"""

# Yearly - Total watt-hour for Power Consumption

df_power_consumption.groupby(df_power_consumption.index.year).sum().plot(kind="bar",xlabel='Year',ylabel='Readings in watt-hour',title="Yearly - Total watt-hour for Power Consumption", figsize=(16,6))

# Yearly - Maximum watt-hour for Power Consumption

df_power_consumption.groupby(df_power_consumption.index.year).max().plot(kind="bar",xlabel='Year',ylabel='Readings in watt-hour',title="Yearly - Maximum watt-hour for Power Consumption", figsize=(16,6))

# Yearly - Minimum watt-hour for Power Consumption

df_power_consumption.groupby(df_power_consumption.index.year).min().plot(kind="bar",xlabel='Year',ylabel='Readings in watt-hour',title="Yearly - Minimum watt-hour for Power Consumption", figsize=(16,6))

# Yearly - Average watt-hour for Power Consumption

df_power_consumption.groupby(df_power_consumption.index.year).mean().plot(kind="bar",xlabel='Year',ylabel='Readings in watt-hour',title="Yearly - Average watt-hour for Power Consumption", figsize=(16,6))

"""###Observation for Yearly Power Consumption (in watt hour)

(Ignoring 2006 year)

1. Total power consumption range is 4000000 - ~5500000 watt hour. i.e., 4000 - ~5500 kWH
2. Maximum Power consumption was done in year 2007
3. Minimum power cosumption was done in year 2010
4. Avearge power consumption is almost same across all years, range is ~12000 WH to ~ 14000 WH *italicized text*
"""

# Checking Statistical summary of power consumption monthly

df_power_consumption.groupby(df_power_consumption.index.month).describe()

# Monthly - Total watt-hour for Power Consumption

df_power_consumption.groupby(df_power_consumption.index.month).sum().plot(kind="bar",xlabel='Month',ylabel='Readings in watt-hour',title="Monthly - Total watt-hour for Power Consumption", figsize=(16,6))

# Monthly - Average watt-hour for Power Consumption

df_power_consumption.groupby(df_power_consumption.index.month).mean().plot(kind="bar",xlabel='Month',ylabel='Readings in watt-hour',title="Monthly - Average watt-hour for Power Consumption", figsize=(16,6))

# Monthly - Minimum watt-hour for Power Consumption

df_power_consumption.groupby(df_power_consumption.index.month).min().plot(kind="bar",xlabel='Month',ylabel='Readings in watt-hour',title="Monthly - Minimum watt-hour for Power Consumption", figsize=(16,6))

# Monthly - Maximum watt-hour for Power Consumption

df_power_consumption.groupby(df_power_consumption.index.month).max().plot(kind="bar",xlabel='Month',ylabel='Readings in watt-hour',title="Monthly - Maximum watt-hour for Power Consumption", figsize=(16,6))

